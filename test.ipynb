{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "#os.system(\"v4l2-ctl --list-devices\")\n",
    "# set format to NTSC, thought PAL is higher resolution.  need to set cameras to PAL\n",
    "for i in range(0, 4):\n",
    "    cmd = f\"v4l2-ctl --device /dev/video{i} --set-standard=ntsc\"\n",
    "    os.system(cmd)\n",
    "\n",
    "cap = [None, None, None]\n",
    "for i in range(0,3):\n",
    "    # Open video capture object\n",
    "    cap[i] = cv2.VideoCapture(i)\n",
    "\n",
    "    # Check if video capture object is successfully opened\n",
    "    if not cap[i].isOpened():\n",
    "        print(\"Failed to open video capture object\")\n",
    "        exit()\n",
    "\n",
    "    #set resolution to 640x480\n",
    "    cap[i].set(3, 720)\n",
    "    cap[i].set(4, 480)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "frame = [None, None, None]\n",
    "cap = [None, None, None]\n",
    "for i in range(0,3):\n",
    "    # Open video capture object\n",
    "    cap[i] = cv2.VideoCapture(i)\n",
    "\n",
    "    # Check if video capture object is successfully opened\n",
    "    if not cap[i].isOpened():\n",
    "        print(\"Failed to open video capture object\")\n",
    "        exit()\n",
    "\n",
    "    #set resolution to 640x480\n",
    "    cap[i].set(3, 720)\n",
    "    cap[i].set(4, 480)\n",
    "\n",
    "for i in range(0,3):\n",
    "\n",
    "    ret, frame[i] = cap[i].read()\n",
    "\n",
    "    # Check if frame is successfully read\n",
    "    if not ret:\n",
    "        print(\"Failed to read frame from video source\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "#create side by side image of i frames\n",
    "frame_combined = cv2.hconcat([frame[0], frame[1], frame[2]])\n",
    "\n",
    "# save image to disk\n",
    "ts = int(time.time())\n",
    "filename = f\"frame_{ts}.jpg\"\n",
    "cv2.imwrite(filename, frame_combined)\n",
    "#print(f\"Frame saved to {filename} size:{frame_combined.shape}\")\n",
    "\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(cv2.cvtColor(frame_combined, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "# Release the video capture object and close any open windows\n",
    "for i in range(0,3):\n",
    "    cap[i].release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pupil_apriltags\n",
    "path = \"/home/casaos/TrailerCamera/\"\n",
    "\n",
    "def point(pt):\n",
    "    return (int(pt[0]),int(pt[1]))\n",
    "\n",
    "def draw_corners(img, detection, color=(255)):\n",
    "    pt1 = point(detection.corners[0])\n",
    "    cv2.circle(img, pt1,5,color,-1)\n",
    "    pt2 = point(detection.corners[1])\n",
    "    cv2.line(img, pt1, pt2,color,2)\n",
    "    pt3 = point(detection.corners[3])\n",
    "    cv2.line(img, pt1, pt3,color,2)\n",
    "    c = point(detection.center)\n",
    "    cv2.circle(img, c,2,color,-1)\n",
    "    cv2.putText(img,str(detection.tag_id), c, cv2.FONT_HERSHEY_PLAIN, 1.5,color,2)\n",
    "\n",
    "\n",
    "w = int(img.shape[1]/3)\n",
    "img_left = img[:,0:w]\n",
    "\n",
    "#mirror image\n",
    "img_left = cv2.flip(img_left, 1)\n",
    "\n",
    "detector = pupil_apriltags.Detector()\n",
    "\n",
    "result = detector.detect(img_left)\n",
    "\n",
    "for i in range(len(result)):\n",
    "   det = result[i]\n",
    "   draw_corners(img_left, det)\n",
    "\n",
    "# show grayscale iamge\n",
    "plt.figure(figsize=(10, 10))  \n",
    "plt.imshow(img_left, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pupil_apriltags\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from AprilBoard import AprilBoard\n",
    "\n",
    "\n",
    "def crop_image(image, bbox_str):\n",
    "    \"\"\"\n",
    "    Crops an image based on a bounding box string format '[top:bottom,left:right]'.\n",
    "\n",
    "    Args:\n",
    "        image: A NumPy array representing the image.\n",
    "        bbox_str: A string representing the bounding box in format '[top:bottom,left:right]'.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the cropped image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        slices = bbox_str.strip('[]').split(',')\n",
    "        top, bottom = map(int, slices[0].split(':'))\n",
    "        left, right = map(int, slices[1].split(':'))\n",
    "    except ValueError:\n",
    "        raise ValueError('Invalid bounding box format. Use [top:bottom,left:right]')\n",
    "\n",
    "    # Crop the image\n",
    "    return image[top:bottom, left:right]\n",
    "\n",
    "\n",
    "def point(pt):\n",
    "    return (int(pt[0]),int(pt[1]))\n",
    "\n",
    "def draw_detection(img, detection, color=(255,0,0)):\n",
    "    pt1 = point(detection.corners[0])\n",
    "    cv2.circle(img, pt1,5,color,-1)\n",
    "    pt2 = point(detection.corners[1])\n",
    "    cv2.line(img, pt1, pt2,color,2)\n",
    "    pt3 = point(detection.corners[3])\n",
    "    cv2.line(img, pt1, pt3,color,2)\n",
    "    c = point(detection.center)\n",
    "    cv2.circle(img, c,2,color,-1)\n",
    "    cv2.putText(img,str(detection.tag_id), c, cv2.FONT_HERSHEY_PLAIN, 1.5,color,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"left\", \"back\", \"right\"]\n",
    "dir = '.'\n",
    "allfiles = os.listdir(dir)\n",
    "images = []\n",
    "calibration_data = {}\n",
    "for f in allfiles:\n",
    "    if \"unwarped\" in f:\n",
    "        continue\n",
    "    if \".jpg\" in f:\n",
    "        images.append(os.path.join(dir,f))\n",
    "\n",
    "    if 'intrinsics' in f:\n",
    "        for n in names:\n",
    "            if n in f:\n",
    "                with open(f,'r') as fp:\n",
    "                    calibration_data[n] = {'intrinsics':json.load(fp)}\n",
    "\n",
    "board = AprilBoard.AprilBoard()\n",
    "detector = pupil_apriltags.Detector()\n",
    "images_unwarped = []\n",
    "\n",
    "for path in images:\n",
    "    print(path)\n",
    "    img_raw = cv2.imread(path)\n",
    "\n",
    "    views = []\n",
    "    for i in range(len(names)):\n",
    "        n = names[i]\n",
    "\n",
    "        K = np.array(calibration_data[n]['intrinsics']['matrix'])\n",
    "        D = np.array(calibration_data[n]['intrinsics']['distortion'])\n",
    "        fisheyeMode = calibration_data[n]['intrinsics']['fisheye']\n",
    "        flip = calibration_data[n]['intrinsics']['flip']\n",
    "        crop = calibration_data[n]['intrinsics']['crop']\n",
    "        img = crop_image(img_raw, crop)\n",
    "        if flip:\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        result = detector.detect(gray)\n",
    "\n",
    "        for detection in result:\n",
    "            draw_detection(img, detection,(0,255,0))\n",
    "        if 'map1' not in calibration_data[name]:\n",
    "            if fisheyeMode:\n",
    "                calibration_data[name]['map1'], calibration_data[name]['map2'] = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, (img.shape[1], img.shape[0]), cv2.CV_16SC2)\n",
    "            else:\n",
    "                calibration_data[name]['map1'], calibration_data[name]['map2'] = cv2.initUndistortRectifyMap(K, D, np.eye(3), K, (img.shape[1], img.shape[0]), cv2.CV_16SC2)\n",
    "        img2 = cv2.remap(img, calibration_data[name]['map1'], calibration_data[name]['map2'], interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "        views.append(img2)\n",
    "\n",
    "    img_concat = cv2.hconcat(views)\n",
    "    images_unwarped.append(img_concat)\n",
    "\n",
    "\n",
    "#show grid of images in unwarped 4 columns no margin\n",
    "cols = 2\n",
    "rows = int(len(images_unwarped)/cols)\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(cols*6*3, rows*4))\n",
    "\n",
    "# Remove space between subplots\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        ax[i,j].imshow(cv2.cvtColor(images_unwarped[i*cols+j], cv2.COLOR_BGR2RGB))\n",
    "        ax[i,j].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
